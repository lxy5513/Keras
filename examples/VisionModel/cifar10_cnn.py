'''
train a simple deep CNN on the CIFAR10 small images dataset 
Epoch 40/100 loss: 0.0023 - acc: 0.7956 - val_loss: 6.4754 - val_acc: 0.5930 

'''
import keras 
import ipdb 
from keras.datasets import cifar10 
from keras.preprocessing.image import ImageDataGenerator 
from keras.models import Sequential 
from keras.layers import Dense, Dropout, Activation, Flatten 
from keras.layers import Conv2D, MaxPooling2D 
import os 

batch_size = 32 
num_classes = 10 
epochs = 100 
data_augmentation = True 
num_predictions = 20 
save_dir = os.path.join(os.getcwd(), 'saved_models')
model_name = 'keras_cifar10_trained_model.h5'

(x_train, y_train), (x_test, y_test) = cifar10.load_data()
print("x_train/y_train shape is {}/{} and its sample num is {}/{}".format(x_train.shape, y_train.shape, x_train.shape[0], y_train.shape[0]))

# before y_train.shape=(5000,1)
# after y_train.shape=(5000,10)
# Convert class vevtors to binary class matrics 
y_train = keras.utils.to_categorical(y_train, num_classes) 
y_test = keras.utils.to_categorical(y_test, num_classes) 

model = Sequential()
model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))
model.add(Activation('relu'))
model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), padding='same', input_shape=x_train.shape[1:]))
model.add(Activation('relu'))
model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes))
model.add(Activation('softmax'))

# intiate RMSprop optimizer 
opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)

model.compile(loss='categorical_crossentropy',
        optimizer=opt,
        metrics=['accuracy'])

x_train = x_train.astype('float32')
y_train = y_train.astype('float32')
x_train /= 255
y_train /= 255

if not data_augmentation:
    print('Not using data augmentation')
    model.fit(x_train, y_train,
            batch_size=batch_size,
            epochs=epochs,
            verbose=1,
            validation_data=(x_test, y_test),
            shuffle=True)

else:
    print("Use real-time data augmentation")
    # 用以生成一个batch的图像数据，支持实时数据提升。训练时该函数会无限生成数据，直到达到规定的epoch次数为止
    datagen = ImageDataGenerator(
            featurewise_center=False,# 是输入的数据集去中心化（均值为0），按feature执行
            samplewise_center=False, # 是输入的数据每个样本均值为0
            featurewise_std_normalization=False, # 将输入除以数据集的标准差以完成标准化，按feature执行 
            samplewise_std_normalization=False, # 将每个样本除以自身的标准差 
            zca_whitening=False, # 对输入数据施加ZCA白化
            zca_epsilon=1e-6, # ZCA使用的eposilion 
            rotation_range=0., # 整数，数据提升时图片随机转动的角度
            width_shift_range=0.1, # 浮点数，图片宽度的某个比例，数据提升时图片水平偏移的幅度
            height_shift_range=0.1, # 浮点数，图片高度的某个比例，数据提升时图片竖直偏移的幅度
            shear_range=0., # 浮点数，剪切强度（逆时针方向的剪切变换角度
            zoom_range=0., # 浮点数或形如[lower,upper]的列表，随机缩放的幅度，若为浮点数，则相当于[lower,upper] = [1 - zoom_range, 1+zoom_range]
            channel_shift_range=0., #浮点数，随机通道偏移的幅度
            fill_mode='nearest', # ‘constant’，‘nearest’，‘reflect’或‘wrap’之一，当进行变换时超出边界的点将根据本参数给定的方法进行处理
            cval=0., # 浮点数或整数，当fill_mode=constant时，指定要向超出边界的点填充的值
            horizontal_flip=True, # 布尔值，进行随机水平翻转
            vertical_flip=False, # 布尔值，进行随机竖直翻转
            rescale=None, #  重放缩因子,默认为None. 如果为None或0则不进行放缩,否则会将该数值乘到数据上(在应用其他变换之前)
            preprocessing_function=None, # 将被应用于每个输入的函数。该函数将在图片缩放和数据提升之后运行。该函数接受一个参数，为一张图片（秩为3的numpy array），并且输出一个具有相同shape的numpy array
            data_format=None, #“channel_last”对应原本的“tf”，“channel_first”对应原本的“th”。以128x128的RGB图像为例，“channel_first”应将数据组织为（3,128,128），而“channel_last”应将数据组织为（128,128,3）
            #  validation_split=0.0
            )
    # compute quantities required for featured for validation (std, mean, and pricipal components if ZCA whitening od apploed
    datagen.fit(x_train)

    # Fit the model on the batches generated by datagen.flow()
    model.fit_generator(datagen.flow(x_train, y_train,
                        batch_size=batch_size),
                        epochs=epochs,
                        validation_data=(x_test, y_test),
                        workers=4)

    if not os.path.isdir(save_dir):
        os.makedirs(save_dir)
    model_path = os.path.join(save_dir, model_name)
    model.save(model_path)
    
    print('Saved trained model at ', model_path)

    scores = model.evaluate(x_test, y_test, verbose=1)
    print('Test loss is {}\tTest accuracy is {}'.format(scores[0], scores[1]))


'''
感悟：
    1. 有些层没有参数 比如：activation flatten dropout poolinglayer 
    2. ImageDataGenerator is a difficult problem 
    3. the usage of model.save() 
    4. fit_generator() 中的 worker and data.flow() 
'''


